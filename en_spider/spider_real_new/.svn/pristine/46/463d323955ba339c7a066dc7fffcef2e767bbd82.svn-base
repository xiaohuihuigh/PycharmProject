爬虫设计文档
============

这个爬虫作为一个统一的爬虫平台来设计,包括实时新闻采集,历史新闻采集,以及一些其他的个性化的周期性和一次性的数据采集项目.

主要部分介绍
+++++++++++

实时新闻
--------

实时新闻的采集,是爬虫平台的核心任务,也是最主要任务.务必要保证实时新闻的正常采集.
实时新闻的主要模块

- main_parse 新闻解析模块 主要负责解析url 以及文章详情页的content提取.
- main_request 请求发送模块 主要负责发送请求.
- items 数据容器模块 主要负责将新闻数据暂时存放在容器里.
- pipelines 数据存储模块 主要负责将数据写入数据库
- settings 设置模块

历史新闻
--------
历史新闻采集的任务已经结束,但是有必要简单记录下相关代码模块.

历史新闻主要放在page_spider目录下.其中的几个模块为:

- spider 初版的历史url新闻采集
- spider_conf 爬虫配置项目(主要用于配置那些在不同服务器上有区别的项,配置后一般不需要更新)
- spider_dev 主要用于开发的测试爬虫
- spider_old 页面采集后,对失败url再采集处理的爬虫
- spider_new 新版历史url新闻采集爬虫
- page_parse 页面解析,主要编写页面解析模块.这一部分,后续应该增加host自动解析模块.
- xpath_pool xpath解析池

其他爬虫
--------
独立的小爬虫,都放在shudan_spider目录下.

- eastmoney_investor_user_parse 采集东方财富相关信息,具体不详细
- save_global_index_price_m1 东方财富全球指数分钟级数据实时采集
- update_investing_data 英为财情,债券,外汇等历史日数据采集,主要用于价格联动分析等涨幅
- wallstreet_calendar 华尔街财经日历采集
- xueqiu_post 雪球网大V文章采集

其他补充
--------

- 实时新闻已经做了额外的监控.其他单独爬虫,还没有编写运行监控脚本.